model_name_or_path: your_model_path
template: qwen3_vl_nothink
infer_backend: vllm  # choices: [huggingface, vllm]
trust_remote_code: true
vllm_enforce_eager: true
max_new_tokens: 10240
vllm_maxlen: 10240